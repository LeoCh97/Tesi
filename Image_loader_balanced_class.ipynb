{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_loader_balanced_class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoCh97/Tesi/blob/master/Image_loader_balanced_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50grapiiG32X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as matplot\n",
        "import os \n",
        "import cv2\n",
        "from tqdm import tqdm_notebook \n",
        "import pandas as pd\n",
        "from imblearn import over_sampling\n",
        "\n",
        "DATADIR1 = \"FlickrLogos-v2/classes/jpg\"\n",
        "DATADIR2 = \"images\"\n",
        "BBDIR1 = \"FlickrLogos-v2/classes/masks\"\n",
        "IMG_SIZE = 128\n",
        "\n",
        "with open(\"Flickrplus_num.txt\", 'r') as f:\n",
        "  if f.mode == 'r':\n",
        "    NUM_OF_IMG = int(f.read())\n",
        "\n",
        "CATEGORIES = []\n",
        "for category in os.listdir(DATADIR1):\n",
        "    if category != \".DS_Store\":\n",
        "        CATEGORIES.append(category)\n",
        "try:\n",
        "  assert len(CATEGORIES) == 33\n",
        "except AssertionError as e:\n",
        "  print(\"Wrong number of classes\", e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzxDG9B7cSZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(CATEGORIES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qbfqDk1CAX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_names = pd.read_csv('FlickrLogos-v2/trainset.txt', header=None, names=['category', 'img_name'])\n",
        "test_data_names = pd.read_csv('FlickrLogos-v2/testset.txt', header=None, names=['category', 'img_name'])\n",
        "val_data_names = pd.read_csv('FlickrLogos-v2/valset.txt', header=None, names=['category', 'img_name'])\n",
        "data_names_plus = pd.read_csv('Flickrplus_groundtruth.txt')\n",
        "\n",
        "data_names_plus = data_names_plus.values.tolist()\n",
        "train_data_names = train_data_names.values.tolist()\n",
        "test_data_names = test_data_names.values.tolist()\n",
        "val_data_names = val_data_names.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hClZVHSkk-hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = []\n",
        "\n",
        "def create_train_data():\n",
        "  for category,img in tqdm_notebook(train_data_names):\n",
        "    if category == \"guiness\":\n",
        "      data_path = os.path.join(DATADIR1, \"guinness\")\n",
        "      bbox_path = os.path.join(BBDIR1, \"guinness\")\n",
        "      data_num = CATEGORIES.index(\"guinness\")\n",
        "    else:\n",
        "      data_path = os.path.join(DATADIR1, category)\n",
        "      bbox_path = os.path.join(BBDIR1, category)\n",
        "      data_num = CATEGORIES.index(category)\n",
        "    \n",
        "    try:\n",
        "      img_array = cv2.imread(os.path.join(data_path,img))\n",
        "      img_bbox = pd.read_csv(os.path.join(bbox_path,img+\".bboxes.txt\"), sep=\" \")\n",
        "      \n",
        "      x = img_bbox['x'][0]\n",
        "      y = img_bbox['y'][0]\n",
        "      w = img_bbox['width'][0]\n",
        "      h = img_bbox['height'][0]\n",
        "      \n",
        "      img_array = img_array[y:y+h, x:x+w]\n",
        "      new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      train_split.append([new_array, data_num])\n",
        "    except Exception as e:\n",
        "      print(\"general exception\", e, os.path.join(data_path,img))\n",
        "    except OSError as e:\n",
        "      print(\"OSError Bad img most likely\", e, os.path.join(data_path,img)) \n",
        "    \n",
        "create_train_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUscaL0Jy7_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_split = []\n",
        "\n",
        "def create_test_data():\n",
        "  for category,img in tqdm_notebook(test_data_names):\n",
        "    if category == \"guiness\":\n",
        "      data_path = os.path.join(DATADIR1, \"guinness\")\n",
        "      bbox_path = os.path.join(BBDIR1, \"guinness\")\n",
        "      data_num = CATEGORIES.index(\"guinness\")\n",
        "    else:\n",
        "      data_path = os.path.join(DATADIR1, category)\n",
        "      bbox_path = os.path.join(BBDIR1, category)\n",
        "      data_num = CATEGORIES.index(category)\n",
        "    \n",
        "    try:\n",
        "      img_array = cv2.imread(os.path.join(data_path,img))\n",
        "      \n",
        "      if category != \"no-logo\":\n",
        "        img_bbox = pd.read_csv(os.path.join(bbox_path,img+\".bboxes.txt\"), sep=\" \")\n",
        "      \n",
        "        x = img_bbox['x'][0]\n",
        "        y = img_bbox['y'][0]\n",
        "        w = img_bbox['width'][0]\n",
        "        h = img_bbox['height'][0]\n",
        "      \n",
        "        img_array = img_array[y:y+h, x:x+w]\n",
        "      \n",
        "      new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      test_split.append([new_array, data_num])\n",
        "    except Exception as e:\n",
        "      print(\"general exception\", e, os.path.join(data_path,img))\n",
        "    except OSError as e:\n",
        "      print(\"OSError Bad img most likely\", e, os.path.join(data_path,img)) \n",
        "    \n",
        "  \n",
        "create_test_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgPvu_MRzoQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_split = []\n",
        "\n",
        "def create_val_data():\n",
        "  for category,img in tqdm_notebook(val_data_names):\n",
        "    if category == \"guiness\":\n",
        "      data_path = os.path.join(DATADIR1, \"guinness\")\n",
        "      bbox_path = os.path.join(BBDIR1, \"guinness\")\n",
        "      data_num = CATEGORIES.index(\"guinness\")\n",
        "    else:\n",
        "      data_path = os.path.join(DATADIR1, category)\n",
        "      bbox_path = os.path.join(BBDIR1, category)\n",
        "      data_num = CATEGORIES.index(category)\n",
        "    \n",
        "    try:\n",
        "      img_array = cv2.imread(os.path.join(data_path,img))\n",
        "      \n",
        "      if category != \"no-logo\":\n",
        "        img_bbox = pd.read_csv(os.path.join(bbox_path,img+\".bboxes.txt\"), sep=\" \")\n",
        "      \n",
        "        x = img_bbox['x'][0]\n",
        "        y = img_bbox['y'][0]\n",
        "        w = img_bbox['width'][0]\n",
        "        h = img_bbox['height'][0]\n",
        "      \n",
        "        img_array = img_array[y:y+h, x:x+w]\n",
        "      \n",
        "      new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      val_split.append([new_array, data_num])\n",
        "    except Exception as e:\n",
        "      print(\"general exception\", e, os.path.join(data_path,img))\n",
        "    except OSError as e:\n",
        "      print(\"OSError Bad img most likely\", e, os.path.join(data_path,img)) \n",
        "    \n",
        "  \n",
        "create_val_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVkaO_K2obRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data_names_plus[NUM_OF_IMG-1][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_F9SY0CmFXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extend_splits():\n",
        "  racoons = 0\n",
        "  (train_elements, val_elements, cat) = (0, 0, data_names_plus[0][1])\n",
        "  \n",
        "  for filename, category, x, y, w, h, bbox in tqdm_notebook(data_names_plus[0:NUM_OF_IMG]):\n",
        "    img_path = os.path.join(DATADIR2, filename)\n",
        "    data_num = CATEGORIES.index(category)\n",
        "    \n",
        "    try:\n",
        "      img = cv2.imread(img_path)\n",
        "      new_array = img[y:y+h, x:x+w]\n",
        "      \n",
        "      new_array = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
        "      \n",
        "      if cat == category:\n",
        "        if train_elements < 80:\n",
        "          train_split.append([new_array, data_num])\n",
        "          train_elements += 1\n",
        "        elif val_elements < 10:\n",
        "          val_split.append([new_array, data_num])\n",
        "          val_elements += 1\n",
        "        else:\n",
        "          test_split.append([new_array, data_num])\n",
        "      else:\n",
        "        (train_elements, val_elements, cat) = (1, 0, category)\n",
        "        train_split.append([new_array, data_num])\n",
        "    except Exception as e:\n",
        "      print(\"general exception\", e, img_path)\n",
        "    except OSError as e:\n",
        "      print(\"OSErrorBad img most likely\", e, img_path) \n",
        "        \n",
        "    try:\n",
        "      for giraffe in range(2, bbox):\n",
        "        x_1 = data_names_plus[NUM_OF_IMG-1+giraffe+racoons][2]\n",
        "        y_1 = data_names_plus[NUM_OF_IMG-1+giraffe+racoons][3]\n",
        "        w_1 = data_names_plus[NUM_OF_IMG-1+giraffe+racoons][4]\n",
        "        h_1 = data_names_plus[NUM_OF_IMG-1+giraffe+racoons][5]\n",
        "        new_array = img[y:y+h, x:x+w]\n",
        "\n",
        "        new_array = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "        if cat == category:\n",
        "          if train_elements < 80:\n",
        "            train_split.append([new_array, data_num])\n",
        "            train_elements += 1\n",
        "          elif val_elements < 10:\n",
        "            val_split.append([new_array, data_num])\n",
        "            val_elements += 1\n",
        "          else:\n",
        "            test_split.append([new_array, data_num])\n",
        "        else:\n",
        "          (train_elements, val_elements, cat) = (1, 1, category)\n",
        "          train_split.append([new_array, data_num])\n",
        "\n",
        "      racoons += bbox - 1\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"general exception 2\", e, img_path)\n",
        "    except OSError as e:\n",
        "      print(\"OSErrorBad img most likely 2\", e, img_path) \n",
        "    \n",
        "    \n",
        "extend_splits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5jKWHEKAaSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(train_split) == 32*90\n",
        "assert len(val_split) == 32*40+3000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQjiI0IM6z__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_split))\n",
        "print(len(test_split))\n",
        "print(len(val_split))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGo3y-9FSEWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(len(CATEGORIES)):\n",
        "  index = 0\n",
        "  for sample in train_split:\n",
        "    if sample[1] == n:\n",
        "      index += 1\n",
        "\n",
        "  print(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PNdIOxZG32v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(train_split)\n",
        "random.shuffle(test_split)\n",
        "random.shuffle(val_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mu2hKB9G32y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sample in train_split[:10]:\n",
        "    print(sample[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68FmAIz9G322",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for features,label in train_split:\n",
        "    X_train.append(features)\n",
        "    y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW_mgrhZ7ESx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for features,label in test_split:\n",
        "    X_test.append(features)\n",
        "    y_test.append(label)\n",
        "\n",
        "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFPx8ITO7Ezu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "for features,label in val_split:\n",
        "    X_val.append(features)\n",
        "    y_val.append(label)\n",
        "\n",
        "X_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTiNpQeCG326",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
        "pickle.dump(X_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y_train.pickle\",\"wb\")\n",
        "pickle.dump(y_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
        "pickle.dump(X_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y_test.pickle\",\"wb\")\n",
        "pickle.dump(y_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"X_val.pickle\",\"wb\")\n",
        "pickle.dump(X_val, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y_val.pickle\",\"wb\")\n",
        "pickle.dump(y_val, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}